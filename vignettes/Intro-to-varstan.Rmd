---
title: "Introduction to varstan"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Intro-to-varstan}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Varstan is a a package for bayesian estimation of structured time series models,using a Hamiltonian monte carlo, implemented with the so popular software "STAN". The aim of varstan is to have an interface of the most popular time series models such as: arima, garch, sarima, stochastic Volatility models (SVM), Hiden Markov models(HMM), seasonal fouier regresi√≥n, additive non-linear models ( [via prophet](https://facebook.github.io/prophet/) ), univariate kalman Filters, varma and bekk models.

On the beta version 0.5.0.000, the avaliable models are:
 
  + arima
  + garch
  + varma

The dynamic of varstan is to build your own model using one of the avaliable model constructor, personalize your own priors (*check the Use Priors vignette*), and fit your model using the varstan function. On the next example we show you how to create and fit a simple bayesian arima model.


```{r message=FALSE}
library(varstan)
library(forecast)
library(bayesplot)
library(ggplot2)
library(gridExtra)
```

First step is make a simulation of a simple arma model with 200 observations as follows:

$$Y_t = \mu_0 + 0.338Y_{t-1} - 0.2279\epsilon_{t-1} - 0.2488\epsilon_{t-2}, \text{ } \epsilon_t \sim N(0,\sigma^2_0)$$

```{r fig.width=7.3}
set.seed(294)
y = arima.sim(n = 700, list(ar =0.35, ma = c(0.2279, 0.2488)),sd = sqrt(0.1796))

autoplot(y)+labs(x = "time",title = "Simulated ARMA Process")
```

Proceding to built the arima model using the varstan constructor:
```{r}
model1 = arima(y,p = 1,d = 0,q = 2)
```

Automatically varstan builds a bayesian arima model, with default normal priors, you can check the model using the report function:

```{r}
report(model1)
```

To Change the prior of one of the defined parameter, just use the set_prior function, in this example we  change the second ma component for a beta distribution on the $\Theta = [-1,1]$ parameter space.

$$\theta_2 \sim beta(2.5,2.5)$$

```{r}
model1 = set_prior(model1,type = "ma",par1 = 2.5,par2 = 2.5,lag = 2,dist = "beta")
get_prior(model1,type = "ma")
```

To see more details of the avaliable priors and the model structure see the vignettes *Use_prior* and *arima_models*, respectively. For estimating the defined model, use the varstan function, it will estimate the posterior sample using a Hamiltonian montecarlo.

In this example a hmc is run with 1 chain of 2000 iterations 

```{r}
sfit = varstan(model1,chains = 1,iter = 2000)
```

summary_varstan, gives a summary of all the fitted parameters, the robust option, prints the median, mad, and quantiles. If the robust option is false, the mean, se and estimated credible intervals are print. The $Rhat$ and efective sample size for preliminary diagnostic if the simulated chains converge to the real value.More detail for parameter diagnostics could be found [here](https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html).

```{r}
summary(sfit,robust= TRUE,conf = 0.95)
```


### Parameter Diagnostic

To get the simulated chain of an specific parameter use the extract_stan function, this is a replication of the [extract](https://mc-stan.org/rstan/reference/stanfit-method-extract.html) function in rstan for varstan objects, an it gets the simulated chains of specified parameters. 

```{r}
post = extract_stan(sfit,pars = "phi",permuted = TRUE,inc_warmup = FALSE,include = TRUE)
post = as.data.frame(post)
```

A simple diagnostic plot for the ar $\phi$ parameter is possible, using the [bayesplot package](https://mc-stan.org/bayesplot/) that visualize posterior distributions and other diagnosis.

```{r fig.width=7.3}
 color_scheme_set("viridis")

  p1 = mcmc_trace(post,  pars = "phi",
        facet_args = list(nrow = 2, labeller = label_parsed)) + 
        facet_text(size = 15)
  p2 = mcmc_hist(post, pars = "phi",facet_args = list(nrow = 2))+
    facet_text(size = 15)
  p3 = mcmc_acf(post, pars = "phi", lags = 10,)
  grid.arrange(p1,p2,p3,nrow = 2,layout_matrix = matrix(c(1,3,2,3),ncol=2,byrow=TRUE))

```

For further exploration and diagnostic use the **get_stan** function to extract the whole rstan fit object and personalize diagnosis using other packages ( [bloo](https://mc-stan.org/loo), [bayesplot](https://mc-stan.org/bayesplot/) ,  [tidybayes](https://github.com/mjskay/tidybayes),  [posterior](https://github.com/jgabry/posterior) ). 

```{r}
stanfit = get_rstan(sfit)
class(stanfit)
```

# The classical arima estimation 

Finally lets compare our results with the clasica arima estimation, as we can see we have similar estimations to the classical model (*due to the low informative prior*)

```{r}
mc = stats::arima(y,order = c(1,0,2))
mc
```

We can compare our residuals with the ones obtained in classical model, and compare. As you will see in the next chunks, they both models have similar results.


The residuals of the classical estimation are:

```{r}
summary(mc$residuals)
```


The posterior mean of the residual statistics of the bayesian model are:
```{r}
resid = residuals(sfit)
summary(resid)
```

And the residual plot for both models are:
```{r fig.width=7.3}
p1 = autoplot(ts(resid))+labs(x = "time",y = "Residuals",title = "Bayesian posterior mean residuals")
p2 = autoplot(mc$residuals)+labs(x = "time",y = "Residuals",title = "Residuals Classic")
 grid.arrange(p1,p2,nrow = 2)
```

