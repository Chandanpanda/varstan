% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/varstan.R
\name{varstan}
\alias{varstan}
\title{Constructor varstan object}
\usage{
varstan(model)
}
\arguments{
\item{model}{One of the varstan model classes defined in the package}

\item{chains}{An integer of the number of Markov Chains chains to be run,
by default 4 chains are run}

\item{iter}{An integer of total iterations per chain including the warm up,
by default  the number of iterations are 2000}

\item{warmup}{A positive integer specifying number of warmup (aka burnin)
iterations. This also specifies the number of iterations used for stepsize
adaptation, so warmup samples should not be used for inference. The number
of warmup should not be larger than \code{iter} and the default is
\code{iter/2}}

\item{adapt.delta}{An optional real value between 0 and 1, the thin of the jumps
in a HMC method. By default is 0.9}

\item{tree.depth}{An integer of the maximum  depth of the trees  evaluated
during each iteration. By default is 10}
}
\value{
a list with the components
\itemize{
 \item stanfit: An stanfit object returned by rstan
 \item model: the current fitted model
 \item stanparams: The stan parameters used in the HMC NUTS algorithm
}
}
\description{
Constructor of the varstan object for bayesian estimation in STAN
}
\details{
The function returns  a list with the data for running stan() function of
 rstan package

If \code{xreg} option is used, the model by default will cancel the
seasonal differences adjusted (D = 0). If a value \code{d} > 0 is used, all
the regressor variables in xreg will be differenced aswell

  Default priors are chosen to be non or very weakly informative so that their
  influence on the results will. However, after getting more familiar with Bayesian
  statistics, I recommend you to start thinking about reasonable informative priors
  for your model parameters. For mor information see \code{set_prior}

  \bold{Adjusting the sampling behavior of \pkg{Stan}}

  In addition to choosing the number of iterations, warmup samples, and
  chains, users can control the behavior of the NUTS sampler, by using the
  \code{control} argument. The most important reason to use \code{control} is
  to decrease (or eliminate at best) the number of divergent transitions that
  cause a bias in the obtained posterior samples. Whenever you see the
  warning "There were x divergent transitions after warmup." you should
  really think about increasing \code{adapt_delta}.  Increasing
  \code{adapt_delta} will slow down the sampler but will decrease the number
  of divergent transitions threatening the validity of your posterior
  samples.

  Another problem arises when the depth of the tree being evaluated in each
  iteration is exceeded. This is less common than having divergent
  transitions, but may also bias the posterior samples. When it happens,
  \pkg{Stan} will throw out a warning suggesting to increase
  \code{max_treedepth}. For more details on the \code{control} argument see
  \code{\link[rstan:stan]{stan}}.
}
\examples{
\dontrun{
# model with the treatment effect
library("astsa")
library("forecast")

# Fitting a seasonal arima model
mod1 = Sarima(birth,order = c(0,1,2),seasonal = c(1,1,1))
fit1 = varstan(mod1,chains = 1)

fit1
}

}
\references{
Carpenter,Gelman,Hoffman, Lee, Goodrich, Betancourt, Brubaker, Guo, Li, and Riddell. 2017.
 Stan: A probabilistic programming language. Journal of Statistical Software 76(1).
 DOI 10.18637/jss.v076.i01

 Stan Development Team. 2018.
 Stan Modeling Language Users Guide and Reference Manual, Version 2.18.0. http://mc-stan.org
}
\seealso{
\code{\link[rstan:stan]{rstan:stan}}.
}
\author{
Asael Alonzo Matamoros
}
